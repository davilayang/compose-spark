version: '3'
x-spark-common:
  &spark-common
  build: 
    context: ./spark_image 
  entrypoint: ["/bin/bash", "/app/start-cluster.sh"]
  environment:
    &spark-common-env
    SPARK_HOME: /opt/spark
    SPARK_WORKER_CORES: 2
    SPARK_WORKER_MEMORY: 4G

services:
  jupyter-server: 
    build: 
      context: ./jupyter_image
    stdin_open: true # docker run -i
    tty: true        # docker run -t
    volumes:
      - ./notebooks:/app/notebooks
      - ./data:/app/data # also mount on workers
    ports: 
      - target: 8888  # container
        published: 8888  # host
        protocol: tcp
        mode: host
  spark-master:
    <<: *spark-common
    ports:
      - 8080:8080 # host:container, web UI
      - 7077:7011 # master port
    environment:
      <<: *spark-common-env
      SPARK_TYPE: master # variable for script, as the master in cluster
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
  spark-worker-1:
    <<: *spark-common
    depends_on:
      - spark-master
    volumes:
      - ./data:/app/data # mock distributed files
    ports:
      - 8081:8081 # web UI
    environment:
      <<: *spark-common-env
      SPARK_MASTER: spark://spark-master:7077 # refers to service "spark-master"
      SPARK_WORKER_WEBUI_PORT: 8081
